{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Collectie van de Gentenaar: Gentse rol van het wc","text":"<pre><code>Bringin heritage closer to the people.\n</code></pre> <p>An installation interpreting images from Collectie van de Gentenaar.</p> <p>The installation places images on a unique timeline, where each image is semantically connected one way or the other.</p> <p>This timeline is then printed on toilet paper.</p> <p>That's about as close as it gets to the people.</p> <p></p>"},{"location":"#oorsprong","title":"Oorsprong","text":"<p>soon</p>"},{"location":"#voortgang","title":"Voortgang","text":"<p>soon</p>"},{"location":"#tech-walkthrough","title":"tech walkthrough","text":"<p>soon</p>"},{"location":"#build-it-yourself","title":"Build it yourself","text":"<p>underneath physical construct you can find : - the Fusion360 model (parameterized for plate thickness) - lasercut files (plate thickness 3.8mm, create new lasercut files via the fusion360 model) - the 3D print models</p> <p>BOM: - Raspberry Pi 4B     - with power supply     - with SC card     - Raspberry pi Camera V3 - Axidraw mini kit 2 - Adafruit DC stepper hat - 2x Nema17 stepper - bolts and nuts - light bulb E14 - light bulb fixation - LCD Keypat hat - large fan (to be defined) - markers     - I used children's markers, as they have a soft tip, useful for toilet paper and they don't dry out. Saves some headaches and running around.</p>"},{"location":"tech_walkthrough/image%20conversion/","title":"Image conversion","text":"<p>Problem: images are mostly camera pictures, high res. Thus we need to convert it to line art to be able to plot it.</p> <p>Found a cool repo: artline, If combined with some tracing programs, this was a good way to go to generate my lineart. Yet due to need of cuda to be able to run it, or need pytorch compiled for CPU. I had a rpi4 lying around, yet immediately getting pytorch (old version!) functioning gave problems with torchvision. I then started looking for some nvidia jetsons, yet apparantly covid chip shortage isn't over yet... So either I had to wait for some jetsons, or recompile pytorch, or go for another approach...</p> <p>I found a different repo which did </p> <p>https://monokai.medium.com/how-to-wirelessly-plot-with-the-axidraw-f9e0a872138e</p> <p>try with e.g. <code>saxi plot -s A5  --pen-down-height 2 --pen-up-height 25 --path-join-radius 1 0.svg</code></p> <p>PLOT with pencil what the borders are of A5, then measure the distance for the toilet paper ==&gt; adapt svgs for this.</p> <p>I've noticed the repo isn't up-to-date anymore and has some issues with polylines, therefore I've adapted my scripts to use only paths in svg. Basically to avoid my lack of js and dependencies.</p>"},{"location":"tech_walkthrough/image%20conversion/#issues-on-the-toilet-paper-front","title":"Issues on the toilet paper front","text":"<ol> <li>paper moving<ol> <li>test with multiple holed plates</li> <li>perhaps stronger suction? </li> </ol> </li> <li>paper ripping with too many lines/ink<ol> <li>lower the amount of lines close to each other?</li> </ol> </li> <li>placement of plotter vs paper <ol> <li>need to have a fixed position!</li> <li>have size fixed in 'saxi' library</li> </ol> </li> <li>pen vs pencil?<ol> <li>test setup</li> </ol> </li> <li>which kind of toilet paper?</li> </ol>"},{"location":"tech_walkthrough/image%20conversion/#platform","title":"platform","text":""},{"location":"tech_walkthrough/image%20conversion/#3d-printed-parts","title":"3D printed parts","text":""},{"location":"tech_walkthrough/image%20conversion/#fixation-for-toilet-paper","title":"fixation for toilet paper","text":"<ul> <li>remove collar</li> <li>2nd part: have fixed size and smaller stem coming out to center</li> <li>hole for stepper to big &amp; not aligning nicely</li> <li>have at the beginning also some support for rolling?</li> </ul>"},{"location":"tech_walkthrough/image%20conversion/#fixation-for-roll-rollers","title":"fixation for roll rollers","text":"<p>2x https://www.thingiverse.com/thing:18019 or 2x https://www.thingiverse.com/thing:990946</p>"},{"location":"tech_walkthrough/image%20conversion/#fixation-for-axi-draw","title":"fixation for axi draw","text":"<p>https://www.thingiverse.com/thing:669325 ==&gt; adapt 1x with extraneous holes for screwing 1x half this design, with extraneous holes</p>"},{"location":"tech_walkthrough/image%20conversion/#connection-for-suction","title":"connection for suction?","text":"<p>kruimeldief</p>"},{"location":"tech_walkthrough/image%20conversion/#platform_1","title":"platform","text":""},{"location":"tech_walkthrough/image%20conversion/#fixations-for-rollers-axi-draw","title":"fixations for rollers &amp; axi draw","text":"<ul> <li>next to each other</li> <li>have not holes, but lines, to be able to align the axi draw &amp; rollers slightly</li> </ul>"},{"location":"tech_walkthrough/image%20conversion/#colored-line","title":"colored line","text":"<p>have a not so comon colour to detect? Or better black, but have image clear of other black things</p>"},{"location":"tech_walkthrough/image%20conversion/#suction-panels","title":"suction panels","text":"<p>3 layer: 1. top layer: multiple hole configurations 2. middle layer: open surface to spread oxygen 3. bottom layer: access for suction pipe glue middle and bottom engrave or route the top and middle one to remove some material. in there we place some rubber or let dry some tec7 (separately) to remove air gaps</p>"},{"location":"tech_walkthrough/image%20conversion/#fixation-for-camera","title":"fixation for camera","text":""},{"location":"tech_walkthrough/image%20conversion/#placement-of-components","title":"placement of components:","text":"<ul> <li>axidraw above the platform</li> <li>rollers beneath the platform</li> <li>camera above the platform raise the platform approx 15cm, keep it tight not to have wiggle when printing</li> </ul> <p>ME311549</p>"},{"location":"tech_walkthrough/path_finding/","title":"Path finding","text":"<p>Idee was startpunt te kiezen, sprong in de tijd maken en een zekere rang behouden. In die range kijken of er matches zijn.</p> <p>Probleem 1: datums in de stream stonden niet mooi en met vreemde karakters ==&gt; dit opkuisen</p> <pre><code>def convert_column_first_year_via_regex(self):  \n    \"\"\"  \n    convert_column_first_year_via_regex is a function that formats the \"converted_creation_date\" column in the pd dataframe to something readable    \n    \"\"\"    \n    res = self.df[self.time_col].str.extract(r\"([\\d+]{4})\").squeeze()  \n    self.df.insert(10, self.clean_time_col, pd.to_numeric(res), True)\n</code></pre> <p>Eerste naieve testcase: ervan uitgaan dat er voldoende data is en kijken of ik, met voldoende tussenstappen (= # wc rol velletjes) voldoende afbeeldingen vind op x afstand en met een link tussen elkaar.</p> <ul> <li>Hoe de link zoeken? Lemmatization vs stemming van geselecteerde kolommen</li> </ul> <p>%%todo: zet tekening van voorbeeld erbij (print statement)%% x afstand: eerst op basis van tijd. Wat bleek: data niet uniform genoeg verspreid en tijd lijkt moeilijke metric. Oplossing: laat tijd los! sorteren van alle entries op basis van tijd, maar dan gewoon sprong maken in de lijst met iedere keer een specifieke afstand en range. Dit komt ongeveer overeen met rekening te houden met de tijdsdistributie en toch te denken in tijd, maar veel gemakkelijker te implementeren.</p> <p>van</p> <pre><code>def find_indices_in_time_range(self, origin_year: int, time_distance: int, time_spread: int) -&gt; (bool, list[int]):  \n    new_origin = origin_year + time_distance  \n    new_time_range = [new_origin - time_spread,  \n                      new_origin + time_spread]  \n    bool_array = self.df.index[  \n        (new_time_range[0] &lt;= self.df[self.clean_time_col]) &amp; (self.df[self.clean_time_col] &lt;= new_time_range[1])]  \n    if len(bool_array) &gt; 0:  \n        res = bool_array.values.tolist()  \n        res_bool = True  \n    else:  \n        res = None  \n        res_bool = False  \n    return res_bool, res\n</code></pre> <p>waar we in tijdstappen dachten naar:</p> <pre><code>def \n</code></pre> <p>Nu hebben we een forward motion die rekening houdt met de distributie ifv de tijd, om een path te vinden moeten we een boomstructuur aanmaken, want het is niet gezegd dat we altijd connecties gaan vinden en af en toe moeten we een tak verlaten en een andere tak uitproberen om tot op het einde te geraken! ==&gt; backward motion</p> <p>Afbeeldingen: de link downloaden: blijkt bij relatief wat afbeeldingen krijg ik geen afbeelding?</p> <pre><code>def get_image_uri(self, img_id) -&gt; str:  \n    iiif_manifest = \"https://api.collectie.gent/iiif/presentation/v2/manifest/{}:{}\".format(self.institute, img_id)  \n    try:  \n        response = urlopen(iiif_manifest)  \n    except ValueError:  \n        print('no image found')  \n    except HTTPError:  \n        print('no image found')  \n    else:  \n        data_json = json.loads(response.read())  \n        image_uri = data_json[\"sequences\"][0]['canvases'][0][\"images\"][0][\"resource\"][\"@id\"]  \n        return image_uri\ndef get_image_list_from_tree(self):  \n    # we pick the rows from our dataframe which were chose  \n    index_list = self.df_tree[self.df_tree[\"chosen\"] == True].index  \n    # based on these indexes we pick the data from within our original dataframe  \n    df_list = self.df.iloc[self.df.index.isin(index_list)]  \n    # we make a list of the objectnumbers, as they are needed to retrieve images  \n    object_id_list = df_list[\"objectnumber\"].values  \n    img_list = list(map(lambda x: self.get_image_uri(x), object_id_list))  \n    for i in img_list:  \n        print(i)  \n    print(len(img_list))\n</code></pre> <p>Got me on a random occasion only 12 out of 50 results. Not good...</p> <p>Plan van aanpak: bij het bouwen van de tree reeds rekening houden met het resultaat van get_image_uri!</p> <p>Nu wordt alles wel heel traag (serieel alle uri's opvragen), dus gaan we threaded werken!</p> <p>Van </p> <pre><code>def find_overlap_in_series(self, origin, indexes) -&gt; (bool, list[dict]):  \n    \"\"\"  \n    @rtype: object  \n    @param origin:    @param indexes:    \"\"\"  \n    print(\"origin:\")  \n    print(self.df_row(origin))  \n    res = list()  \n    res_found = False  \n\n    for i in indexes:  \n        if i == origin:  \n            continue  \n        # print(self.df_row(i))  \n        overlap_found, overlap_list, img_uri = self.find_overlap(origin, i)  \n        if overlap_found:  \n            print(Fore.GREEN)  \n            print(overlap_list)  \n            res.append({\"index\": i, \"res\": overlap_list, \"img_uri\": img_uri})  \n            res_found = True  \n        else:  \n            # print(Fore.RED + \"nothing found\")  \n            continue  \n        print(Style.RESET_ALL)  \n    return res_found, res\n</code></pre> <p>Naar threaded:</p> <pre><code>\ndef find_overlap_threaded_in_series(self, origin, indexes) -&gt; (bool, list[dict], list[str]):  \n    \"\"\"  \n    TODO not satisfied with this, not functionally written!  \n    @rtype: object  \n    @param origin: the index in the original dataframe for which we're looking for childs in &lt;indexes&gt; with a textual overlap    @param indexes: the indexes of possible children    \"\"\"  \n    print(\"origin:\")  \n    print(self.df_row(origin))  \n    res = list()  \n    res_found = False  \n\n    # we'll multithread the find_overlap function to speed things up  \n    que = Queue()  \n    threads_list = list()  \n    for i in indexes:  \n        if i == origin:  \n            continue  \n        t = Thread(target=lambda q, arg1, arg2: q.put(self.find_overlap(arg1, arg2)), args=(que, origin, i))  \n        t.start()  \n        threads_list.append(t)  \n    for t in threads_list:  \n        t.join()  \n    while not que.empty():  \n        overlap_found, overlap_list, img_uri, index = que.get()  \n        if overlap_found:  \n            print(Fore.GREEN)  \n            print(overlap_list)  \n            res.append({\"index\": index, \"res\": overlap_list, \"img_uri\": img_uri})  \n            res_found = True  \n        else:  \n            # print(Fore.RED + \"nothing found\")  \n            continue  \n        print(Style.RESET_ALL)  \n    return res_found, res\n</code></pre> <p>Now, my algorithm is basically: - You have a startnode - Find all indices we want to evaluate - Find all childs based on the indices which have a textual overlap with our startnode - choose one of them as a new startnode     - If no child nodes are to be found, switch the new startnode</p> <p>As this takes a long time, perhaps it's faster for future reference to NOT choose the new startnode, yet search childs with overlaps for all nested childs. This implicates: - more memory usage - small rewriting part (not choosing one branch + keeping track of the parent) - if the database is renewed, entire process needs to be redone.</p> <p>So I've rewritten my flow for easier reuse: - instead of finding a unique path and only saving this path towards the end - I build the entire tree structure - and find a possible path afterwards - This way making it possible to recuperate the builded tree structure. As I only keep a link to the images, I don't have this huge memory bounty.</p> <p>Now, after having some hassles rewriting the code in threads. It takes a long time to make the tree structure. That made me think that I check often for the same entry if there's an image present as they appear in different branches. Thus, I'll rewrite the code again to add the uri, if available, to the original dataframe. Then I don't need to have so many requests (which is the bottleneck, together with my sense of patience)</p> <p>I now preprocess the data to first go through all images and find their URI, if there's none I don't keep them.  My initial plan was to process all data into a tree, yet after running an entire night I came to next conclusion: it's becoming way to large and slow. I need 50 layers, by morning I had 9 (with 1000 threads in parallel, and a spread of 3):</p> <ul> <li>layer 1: 1 id to check @ 22:25:34</li> <li>layer 2: 5 ids to check</li> <li>layer 3: 30 ids to check</li> <li>layer 4: 150 ids to check</li> <li>layer 5: 738 ids to check</li> <li>layer 6: 3947</li> <li>layer 7: 19849</li> <li>layer 8: 94446</li> <li>layer 9: 444545  (400000 @ 08:35:35) ==&gt; I'm not that patient!</li> </ul> <p>each 1000 threads took approx 2 minutes at layer 9. Perhaps my dataframe is becoming too large to be efficient... At layer 8 it was about 20 seconds...</p> <p>So I went for again a different approach: - first check for each entry if there's an image present as well as a useful date. Other entries I drop.     - Especially the image present gave a huge dropout:         - for dmg: out of 9142 ids, we got next HTTP errors: {'403': 1245, '404': 6789, '502': 18}         - in DMG there are some weird object ids: <code>/iiif/presentation/v2/manifest/dmg:DES. 1995.16_0-2</code> what's the space doing there? the object can't be found + throws an error          - for hva: <code>of 8574 ids, we got next HTTP errors: {'403': 9, '404': 6700, '502': 2}</code></p>"}]}